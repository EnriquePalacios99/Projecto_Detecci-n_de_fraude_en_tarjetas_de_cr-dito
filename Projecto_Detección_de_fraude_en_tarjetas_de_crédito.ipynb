{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecto:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de fraude en tarjetas de crédito \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una compañia financiera quiere encontrar los patrones en los fraudes de las tarjetas de crédito que se encuentran en su compañia, ya que estan ocacionando gastos terribles y necesitan encontrar el problema. En ese sentido, el equipo de ciencia de datos esta encargado de encontrar un modelo idodeo para verificar estos fraudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El autoenconder es una especie de arquitecturas de aprendizaje profundo. La arquitectura del codificador automatico comprende dos subsistemas como codificador y decodificador. Ambos subsistemas estan formados por una red neuronal independiente con un conkunto definido de capas y funciones de activación. El rasgo carasteristico fundamental de la arquitectura Autenconder es extraer los puntos de los datos latentes (ocultos) del conunto de datos dados.\n",
    "\n",
    "Como siguiere el nombre, el codificador automatico tiene como objetivo aprender a codificar una represebtacuón de datos de muestra de entrenamiento automaticamente sin intervencion humana\n",
    "\n",
    "El autocodificador se usa ampliamente para la reducción de dimensionalidad y eliminación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construcción de un autoenconder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La construcción de un codificador automático normalmente tendrá tres elementos:\n",
    "1. Función de codificación para mapear la entrada a una representación oculta a través de una función no lineal, $z = sigmoid(W x + b)$\n",
    "2. Una función de decodificación como $x = sigmoidea(W'y + b′)$, que se mapeará de nuevo en la reconstrucción $x'$con la misma forma que x\n",
    "3. Una función de pérdida, que es una función de distancia para medir la pérdida de información entre la representación comprimida de datos y la representación\n",
    "descomprimida. El error de reconstrucción se puede medir utilizando el error cuadrado tradicional $||x-z||^2$\n",
    "Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Elegir las funciones de activación adecuadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la elección más adecuada para una red neural?\n",
    "Quizás se pregunte cómo elegir la función de activación adecuada para sus redes neuronales. A continuación, se ofrecen respuestas detalladas sobre cuándo elegir\n",
    "una función de activación en particular:\n",
    "* Lineal: $f(z) = z$. Puede interpretar esto como una función de no activación. Por lo general, lo usamos en la capa de salida en redes de regresión, ya que no\n",
    "necesitamos ninguna transformación en las salidas.\n",
    "* Sigmoide (logística): transforma la salida de una capa en un rango entre 0 y 1. Puede interpretarlo como la probabilidad de una predicción de salida. Por lo\n",
    "tanto, lo usamos generalmente en la capa de salida en redes de clasificación binaria. Además de eso, a veces lo usamos en capas ocultas. Sin embargo, cabe\n",
    "señalar que la función sigmoidea es monótona pero su derivada no lo es. Por lo tanto, la red neuronal puede atascarse en una solución suboptima.\n",
    "* Softmax:. softmax es una función logística generalizada que se utiliza para la clasificación multiclase. Por lo tanto, lo usamos en la capa de salida en redes de\n",
    "clasificación multiclase.\n",
    "* Tanh: es una mejor versión de la función sigmoidea con gradientes más fuertes. Como puede ver en los gráficos, las derivadas de la función tanh son más\n",
    "pronunciadas que las de la función sigmoidea. Tiene un rango de -1 a 1. Es común usar la función tanh en capas ocultas.\n",
    "* ReLU: es probablemente la función de activación más utilizada en la actualidad. Es el \"predeterminado\" en capas ocultas en redes feedforward. Su rango es de 0\n",
    "a infinito, y tanto la función en sí como su derivada son monótonas. Un inconveniente de la función ReLU es la incapacidad de mapear adecuadamente la parte\n",
    "negativa de la entrada donde todas las entradas negativas se transforman a cero. Para solucionar el problema del \"negativo moribundo\" en ReLU, se inventó eaky ReLU para introducir una pequeña pendiente en la parte negativa. Cuando $z < 0, f(z) = az$, donde a suele ser un valor pequeño, como 0,01.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Transacciones con tarjeta de crédito y dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos que usaremos en este cuaderno es creditcard.csv, que básicamente era una transacción con tarjeta de crédito en el pasado. Mediante un\n",
    "sistema codificador-decodificador encontraremos los puntos de datos ocultos y aplicaremos un clasificador lineal para detectar las transacciones de tarjetas de\n",
    "crédito Fraude (1) o Genuine / no fraude (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Importar las librerias iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "hlNfrSC1PGfZ"
   },
   "outputs": [],
   "source": [
    "#Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#SKLearn related libraries\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Clasificadores\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metricas\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras NN related libraries\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Cargar la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "W0CTsNioTKnJ"
   },
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos en un Pandas DataFrame\n",
    "card_df = pd.read_csv('creditcard.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "o_iMfyHsTa6s",
    "outputId": "318bdb4d-9f20-4789-c6e6-9b2de1aad091"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeras 5 filas del conjunto de datos\n",
    "card_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "iWCP6YJjThIM",
    "outputId": "19097c05-c0ff-4df7-c21b-84c7cde9e7da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcCZquvEUD3A",
    "outputId": "a18d75ef-936b-4a52-8589-0acb2cc5fe4e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "========================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Información del conjunto de datos\n",
    "card_df.info()\n",
    "print(\"====\"*30)\n",
    "card_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxwasmfKUQiA",
    "outputId": "a1cf3e15-9491-40f9-fecb-e5d1895bc8ca",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobación del número de valores que faltan en cada columna\n",
    "card_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Análisis Exploratorio de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visualizando estadisticas descriptiva de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.772925e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.289524e-16</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.803266e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.674888e-15</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.475621e-15</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.501098e-15</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.392460e-15</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-7.466538e-16</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.258754e-16</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.019919e-16</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.126845e-16</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%  \\\n",
       "Time    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000   \n",
       "V1      284807.0  3.918649e-15      1.958696  -56.407510     -0.920373   \n",
       "V2      284807.0  5.682686e-16      1.651309  -72.715728     -0.598550   \n",
       "V3      284807.0 -8.761736e-15      1.516255  -48.325589     -0.890365   \n",
       "V4      284807.0  2.811118e-15      1.415869   -5.683171     -0.848640   \n",
       "V5      284807.0 -1.552103e-15      1.380247 -113.743307     -0.691597   \n",
       "V6      284807.0  2.040130e-15      1.332271  -26.160506     -0.768296   \n",
       "V7      284807.0 -1.698953e-15      1.237094  -43.557242     -0.554076   \n",
       "V8      284807.0 -1.893285e-16      1.194353  -73.216718     -0.208630   \n",
       "V9      284807.0 -3.147640e-15      1.098632  -13.434066     -0.643098   \n",
       "V10     284807.0  1.772925e-15      1.088850  -24.588262     -0.535426   \n",
       "V11     284807.0  9.289524e-16      1.020713   -4.797473     -0.762494   \n",
       "V12     284807.0 -1.803266e-15      0.999201  -18.683715     -0.405571   \n",
       "V13     284807.0  1.674888e-15      0.995274   -5.791881     -0.648539   \n",
       "V14     284807.0  1.475621e-15      0.958596  -19.214325     -0.425574   \n",
       "V15     284807.0  3.501098e-15      0.915316   -4.498945     -0.582884   \n",
       "V16     284807.0  1.392460e-15      0.876253  -14.129855     -0.468037   \n",
       "V17     284807.0 -7.466538e-16      0.849337  -25.162799     -0.483748   \n",
       "V18     284807.0  4.258754e-16      0.838176   -9.498746     -0.498850   \n",
       "V19     284807.0  9.019919e-16      0.814041   -7.213527     -0.456299   \n",
       "V20     284807.0  5.126845e-16      0.770925  -54.497720     -0.211721   \n",
       "V21     284807.0  1.473120e-16      0.734524  -34.830382     -0.228395   \n",
       "V22     284807.0  8.042109e-16      0.725702  -10.933144     -0.542350   \n",
       "V23     284807.0  5.282512e-16      0.624460  -44.807735     -0.161846   \n",
       "V24     284807.0  4.456271e-15      0.605647   -2.836627     -0.354586   \n",
       "V25     284807.0  1.426896e-15      0.521278  -10.295397     -0.317145   \n",
       "V26     284807.0  1.701640e-15      0.482227   -2.604551     -0.326984   \n",
       "V27     284807.0 -3.662252e-16      0.403632  -22.565679     -0.070840   \n",
       "V28     284807.0 -1.217809e-16      0.330083  -15.430084     -0.052960   \n",
       "Amount  284807.0  8.834962e+01    250.120109    0.000000      5.600000   \n",
       "Class   284807.0  1.727486e-03      0.041527    0.000000      0.000000   \n",
       "\n",
       "                 50%            75%            max  \n",
       "Time    84692.000000  139320.500000  172792.000000  \n",
       "V1          0.018109       1.315642       2.454930  \n",
       "V2          0.065486       0.803724      22.057729  \n",
       "V3          0.179846       1.027196       9.382558  \n",
       "V4         -0.019847       0.743341      16.875344  \n",
       "V5         -0.054336       0.611926      34.801666  \n",
       "V6         -0.274187       0.398565      73.301626  \n",
       "V7          0.040103       0.570436     120.589494  \n",
       "V8          0.022358       0.327346      20.007208  \n",
       "V9         -0.051429       0.597139      15.594995  \n",
       "V10        -0.092917       0.453923      23.745136  \n",
       "V11        -0.032757       0.739593      12.018913  \n",
       "V12         0.140033       0.618238       7.848392  \n",
       "V13        -0.013568       0.662505       7.126883  \n",
       "V14         0.050601       0.493150      10.526766  \n",
       "V15         0.048072       0.648821       8.877742  \n",
       "V16         0.066413       0.523296      17.315112  \n",
       "V17        -0.065676       0.399675       9.253526  \n",
       "V18        -0.003636       0.500807       5.041069  \n",
       "V19         0.003735       0.458949       5.591971  \n",
       "V20        -0.062481       0.133041      39.420904  \n",
       "V21        -0.029450       0.186377      27.202839  \n",
       "V22         0.006782       0.528554      10.503090  \n",
       "V23        -0.011193       0.147642      22.528412  \n",
       "V24         0.040976       0.439527       4.584549  \n",
       "V25         0.016594       0.350716       7.519589  \n",
       "V26        -0.052139       0.240952       3.517346  \n",
       "V27         0.001342       0.091045      31.612198  \n",
       "V28         0.011244       0.078280      33.847808  \n",
       "Amount     22.000000      77.165000   25691.160000  \n",
       "Class       0.000000       0.000000       1.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las clases únicas en el conjunto de datos son : [0 1]\n"
     ]
    }
   ],
   "source": [
    "#Etiquetas de la clase o target\n",
    "print(f\"Las clases únicas en el conjunto de datos son : {np.unique(card_df['Class'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIpoKfp5Ugri",
    "outputId": "5150aa81-723c-424d-dcee-80f5c1e37a0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribución de transacciones legítimas y transacciones fraudulentas\n",
    "card_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graficamos la distribución de los datos\n",
    "card_df.groupby('Class')['Class'].count().plot.bar(logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OlMhkHzVKMv"
   },
   "source": [
    "Encontramos dos divisiones de transacciones normales y fraudulentas\n",
    "\n",
    "0 --> Transacción normal\n",
    "\n",
    "1 --> Transacción fraudulentaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "QNn77bdbU2Lf"
   },
   "outputs": [],
   "source": [
    "# Separar los datos para el análisis\n",
    "legit = card_df[card_df.Class == 0]\n",
    "fraud = card_df[card_df.Class == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsrMgOdoVnrV",
    "outputId": "3ca353f2-4339-435e-9e5b-b4080bf7f608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284315, 31)\n",
      "(492, 31)\n"
     ]
    }
   ],
   "source": [
    "print(legit.shape)\n",
    "print(fraud.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La transformación de datos es uno de los pasos del procesamiento de datos. Necesitamos transformar el valor de ciertos atributos para que tenga sentido en el\n",
    "análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar la variable time a dias\n",
    "card_df['Time'] = card_df['Time'].apply(lambda t: (t/3600) % 24)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra de la data\n",
    "#normal_trans = card_df[card_df[ 'class'] == 0]. sample (frac=0.5)\n",
    "normal_trans = card_df[card_df['Class']==0].sample(4000)\n",
    "fraud_trans = card_df [card_df ['Class'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enriq\\AppData\\Local\\Temp\\ipykernel_13916\\4007564440.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  reduced_set = normal_trans.append(fraud_trans).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "reduced_set = normal_trans.append(fraud_trans).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma limpiada del conjunto de datos: (4492, 31)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forma limpiada del conjunto de datos: {reduced_set.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into x and y features\n",
    "y = reduced_set['Class']\n",
    "X = reduced_set.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Features: (4492, 30) and Target: (4492,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Features: {X.shape} and Target: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualice los datos con t-SNE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TNSE (incrustación de vecinos estocásticos distribuidos en t) es uno de los métodos de reducción de dimensionalidad distintos de PCA y SVD. Esto suprimirá algo\n",
    "de ruido y acelerará el cálculo de la distancia por pares entre muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality_plot(X, y):\n",
    "    sns.set(style='whitegrid', palette='muted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing TSNE object with 2 principal components\n",
    "tsne = TSNE(n_components=2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the data\n",
    "X_trans = tsne.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.scatter(X_trans[np.where(y == 0), 0], X_trans[np.where(y==0), 1],marker='o', color='g', linewidths=1, alpha=0.8, label='Normal')\n",
    "plt.scatter(X_trans[np.where(y == 1), 0], X_trans[np.where(y==1), 1], marker='o', color='k', linewidths=1, alpha=0.8, label='Fraud')\n",
    "\n",
    "plt.legend (loc = 'best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficando las dimensionalidad\n",
    "dimensionality_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de Modelo Autoencoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de los datos de entrada: 30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forma de los datos de entrada: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo autoencoder. Como necesitamos acceder a la salida de la etapa del encoder, necesitaremos definir el modelo utilizando un método\n",
    "ligeramente diferente al utilizado anteriormente. Defina una capa de entrada de 30 unidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capa de entrada con forma de los features / columnas del conjunto de datos\n",
    "input_layer = Input(shape = (X.shape[1], ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina una Dense layer posterior de 100 unidades respectivamente y una función de activación de tanh como etapa de codificación. Tenga en cuenta que hemos\n",
    "asignado el layer a una variable y pasado la capa anterior a un método de llamada para la clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construcción del enconder network\n",
    "encoded = Dense(100, activation= 'tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoded = Dense(50, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "encoded = Dense(25, activation= 'tanh', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "encoded = Dense(12, activation= 'tanh', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "encoded = Dense(6, activation= 'relu')(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder network\n",
    "decoded = Dense(12, activation='tanh')(encoded)\n",
    "decoded = Dense(25, activation='tanh')(decoded)\n",
    "decoded = Dense(50, activation='tanh')(decoded)\n",
    "decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "output_layer = Dense(X.shape[1], activation='relu')(decoded)\n",
    "\n",
    "# Building a model\n",
    "auto_encoder = Model(input_layer, output_layer)\n",
    "#Compile the auto encoder model\n",
    "auto_encoder.compile(optimizer='Adadelta', loss='mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and Scale the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler().fit_transform(X)\n",
    "\n",
    "# Scaled data\n",
    "X_scaled_normal = scaler[y == 0]\n",
    "X_scaled_fraud = scaler[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 2s 5ms/step - loss: 1.2821 - val_loss: 1.5613\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2816 - val_loss: 1.5608\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2811 - val_loss: 1.5604\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2806 - val_loss: 1.5599\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2801 - val_loss: 1.5594\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2796 - val_loss: 1.5590\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2791 - val_loss: 1.5585\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2786 - val_loss: 1.5581\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2782 - val_loss: 1.5577\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2777 - val_loss: 1.5572\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2772 - val_loss: 1.5568\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2767 - val_loss: 1.5563\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2762 - val_loss: 1.5559\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2758 - val_loss: 1.5554\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2753 - val_loss: 1.5550\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2748 - val_loss: 1.5545\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2743 - val_loss: 1.5541\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2738 - val_loss: 1.5536\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2734 - val_loss: 1.5532\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.2729 - val_loss: 1.5527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276ae5a4e80>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the auto encoder model\n",
    "auto_encoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "# Training the auto encoder model\n",
    "auto_encoder.fit(X_scaled_normal, X_scaled_normal, batch_size=32, epochs=20, shuffle=True, validation_split=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Autoencode to encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_model = Sequential()\n",
    "latent_model.add(auto_encoder.layers[0])\n",
    "latent_model.add(auto_encoder.layers[1])\n",
    "latent_model.add(auto_encoder.layers[2])\n",
    "latent_model.add(auto_encoder.layers[3])\n",
    "latent_model.add(auto_encoder.layers[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 906us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "normal_tran_points = latent_model.predict(X_scaled_normal)\n",
    "fraud_tran_points = latent_model.predict(X_scaled_fraud)\n",
    "# Making as a one collection\n",
    "encoded_X = np.append(normal_tran_points, fraud_tran_points, axis=0)\n",
    "y_normal = np.zeros(normal_tran_points.shape[0])\n",
    "y_fraud = np.ones(fraud_tran_points.shape[0])\n",
    "encoded_y = np.append(y_normal, y_fraud, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling TSNE plot function\n",
    "dimensionality_plot(encoded_X, encoded_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the encoded fraud data points have been moved towards one cluster, whereas there are only few fraud transaction datapoints are there among the normal transaction data points. \n",
    "\n",
    "## Split into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_enc_train, X_enc_test, y_enc_train, y_enc_test = train_test_split(encoded_X, encoded_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of SVM\n",
    "svc_clf = SVC()\n",
    "\n",
    "svc_clf.fit(X_train, y_train)\n",
    "\n",
    "svc_predictions = svc_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1188\n",
      "           1       1.00      0.50      0.67       160\n",
      "\n",
      "    accuracy                           0.94      1348\n",
      "   macro avg       0.97      0.75      0.82      1348\n",
      "weighted avg       0.94      0.94      0.93      1348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report \\n {0}\".format(classification_report(y_test, svc_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier\n",
    "\n",
    "Now let's apply linear classifier to classify the data and observe the result. We will use **Logistic Regression** to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_enc_train, y_enc_train)\n",
    "\n",
    "# Predict the Test data\n",
    "predictions = lr_clf.predict(X_enc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      1198\n",
      "         1.0       0.98      0.72      0.83       150\n",
      "\n",
      "    accuracy                           0.97      1348\n",
      "   macro avg       0.97      0.86      0.91      1348\n",
      "weighted avg       0.97      0.97      0.97      1348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report \\n {0}\".format(classification_report(y_enc_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is : 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score is : {:.2f}\".format(accuracy_score(y_enc_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this analysis, we have found that Support Vector Machine classifier is able to classify the data upto **93%** without encoding and decoding. However, the effect of autoencoder comes when the data gets transformed from non-linear to linearly separable then linear classifier like **Logistic Regression** could perform in a better way.\n",
    "\n",
    "The accuracy score of Logistic Regression can go upto **97%**, this is something not happens too often in logistic algorithm. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
